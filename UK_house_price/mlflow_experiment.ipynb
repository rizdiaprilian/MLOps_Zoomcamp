{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "\n",
    "\n",
    "# see the named configure in aws configure\n",
    "os.environ[\"AWS_PROFILE\"] = \"profilename\" \n",
    "\n",
    "TRACKING_SERVER_HOST = \"Public IPv4 DNS\" # fill in with the public DNS of the EC2 instance\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, run command `mlflow server -h 0.0.0.0 -p 5000 --backend-store-uri sqlite:///mlflow_uk_house.db --default-artifact-root s3://mlopszoomcamp-bucket`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='./mlruns/0', experiment_id='0', lifecycle_stage='active', name='Default', tags={}>,\n",
       " <Experiment: artifact_location='./mlruns/1', experiment_id='1', lifecycle_stage='active', name='prefect-forecasting', tags={}>,\n",
       " <Experiment: artifact_location='s3://mlopszoomcamp-bucket/', experiment_id='4', lifecycle_stage='active', name='forecasting', tags={}>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.list_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-28 13:26:21 mlopszoomcamp-bucket\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./mlruns/0/cc43081781244f61a677a007fcbe3971/artifacts'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.get_artifact_uri()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of places in UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/uk_house_price\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "col1 = [\"Average_Price\", \"Average_Price_SA\"]\n",
    "col2 = [\"Monthly_Change\", \"Annual_Change\"]\n",
    "NEW_PATH = os.path.join(Path.cwd().parents[3],\"data\",\"uk_house_price\")\n",
    "\n",
    "print(NEW_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(NEW_PATH, 'Average_price-2022-02_from2000.csv')\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df2 = df.drop(\"Unnamed: 0\", axis=1)\n",
    "df2[\"Date\"] = pd.to_datetime(df2.Date)\n",
    "df2[col1] = df2[col1].astype(\"float32\")\n",
    "df2[col2] = df2[col2].astype(\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aberdeenshire',\n",
       " 'Adur',\n",
       " 'Allerdale',\n",
       " 'Amber Valley',\n",
       " 'Angus',\n",
       " 'Antrim and Newtownabbey',\n",
       " 'Ards and North Down',\n",
       " 'Argyll and Bute',\n",
       " 'Armagh City Banbridge and Craigavon',\n",
       " 'Arun',\n",
       " 'Ashfield',\n",
       " 'Ashford',\n",
       " 'Babergh',\n",
       " 'Barking and Dagenham',\n",
       " 'Barnet',\n",
       " 'Barnsley',\n",
       " 'Barrow-in-Furness',\n",
       " 'Basildon',\n",
       " 'Basingstoke and Deane',\n",
       " 'Bassetlaw',\n",
       " 'Bath and North East Somerset',\n",
       " 'Bedford',\n",
       " 'Belfast',\n",
       " 'Bexley',\n",
       " 'Birmingham',\n",
       " 'Blaby',\n",
       " 'Blackburn with Darwen',\n",
       " 'Blackpool',\n",
       " 'Blaenau Gwent',\n",
       " 'Bolsover',\n",
       " 'Bolton',\n",
       " 'Boston',\n",
       " 'Bournemouth Christchurch and Poole',\n",
       " 'Bracknell Forest',\n",
       " 'Bradford',\n",
       " 'Braintree',\n",
       " 'Breckland',\n",
       " 'Brent',\n",
       " 'Brentwood',\n",
       " 'Bridgend',\n",
       " 'Brighton and Hove',\n",
       " 'Broadland',\n",
       " 'Bromley',\n",
       " 'Bromsgrove',\n",
       " 'Broxbourne',\n",
       " 'Broxtowe',\n",
       " 'Buckinghamshire',\n",
       " 'Burnley',\n",
       " 'Bury',\n",
       " 'Caerphilly',\n",
       " 'Calderdale',\n",
       " 'Cambridge',\n",
       " 'Cambridgeshire',\n",
       " 'Camden',\n",
       " 'Cannock Chase',\n",
       " 'Canterbury',\n",
       " 'Cardiff',\n",
       " 'Carlisle',\n",
       " 'Carmarthenshire',\n",
       " 'Castle Point',\n",
       " 'Causeway Coast and Glens',\n",
       " 'Central Bedfordshire',\n",
       " 'Ceredigion',\n",
       " 'Charnwood',\n",
       " 'Chelmsford',\n",
       " 'Cheltenham',\n",
       " 'Cherwell',\n",
       " 'Cheshire East',\n",
       " 'Cheshire West and Chester',\n",
       " 'Chesterfield',\n",
       " 'Chichester',\n",
       " 'Chorley',\n",
       " 'City of Aberdeen',\n",
       " 'City of Bristol',\n",
       " 'City of Derby',\n",
       " 'City of Dundee',\n",
       " 'City of Edinburgh',\n",
       " 'City of Glasgow',\n",
       " 'City of Kingston upon Hull',\n",
       " 'City of London',\n",
       " 'City of Nottingham',\n",
       " 'City of Peterborough',\n",
       " 'City of Plymouth',\n",
       " 'City of Westminster',\n",
       " 'Clackmannanshire',\n",
       " 'Colchester',\n",
       " 'Conwy',\n",
       " 'Copeland',\n",
       " 'Cornwall',\n",
       " 'Cotswold',\n",
       " 'County Durham',\n",
       " 'Coventry',\n",
       " 'Craven',\n",
       " 'Crawley',\n",
       " 'Croydon',\n",
       " 'Cumbria',\n",
       " 'Dacorum',\n",
       " 'Darlington',\n",
       " 'Dartford',\n",
       " 'Denbighshire',\n",
       " 'Derbyshire',\n",
       " 'Derbyshire Dales',\n",
       " 'Derry City and Strabane',\n",
       " 'Devon',\n",
       " 'Doncaster',\n",
       " 'Dorset',\n",
       " 'Dover',\n",
       " 'Dudley',\n",
       " 'Dumfries and Galloway',\n",
       " 'Ealing',\n",
       " 'East Ayrshire',\n",
       " 'East Cambridgeshire',\n",
       " 'East Devon',\n",
       " 'East Dunbartonshire',\n",
       " 'East Hampshire',\n",
       " 'East Hertfordshire',\n",
       " 'East Lindsey',\n",
       " 'East Lothian',\n",
       " 'East Midlands',\n",
       " 'East Renfrewshire',\n",
       " 'East Riding of Yorkshire',\n",
       " 'East Staffordshire',\n",
       " 'East Suffolk',\n",
       " 'East Sussex',\n",
       " 'East of England',\n",
       " 'Eastbourne',\n",
       " 'Eastleigh',\n",
       " 'Eden',\n",
       " 'Elmbridge',\n",
       " 'Enfield',\n",
       " 'England',\n",
       " 'England and Wales',\n",
       " 'Epping Forest',\n",
       " 'Epsom and Ewell',\n",
       " 'Erewash',\n",
       " 'Essex',\n",
       " 'Exeter',\n",
       " 'Falkirk',\n",
       " 'Fareham',\n",
       " 'Fenland',\n",
       " 'Fermanagh and Omagh',\n",
       " 'Fife',\n",
       " 'Flintshire',\n",
       " 'Folkestone and Hythe',\n",
       " 'Forest of Dean',\n",
       " 'Fylde',\n",
       " 'Gateshead',\n",
       " 'Gedling',\n",
       " 'Gloucester',\n",
       " 'Gloucestershire',\n",
       " 'Gosport',\n",
       " 'Gravesham',\n",
       " 'Great Britain',\n",
       " 'Great Yarmouth',\n",
       " 'Greater Manchester',\n",
       " 'Greenwich',\n",
       " 'Guildford',\n",
       " 'Gwynedd',\n",
       " 'Hackney',\n",
       " 'Halton',\n",
       " 'Hambleton',\n",
       " 'Hammersmith and Fulham',\n",
       " 'Hampshire',\n",
       " 'Harborough',\n",
       " 'Haringey',\n",
       " 'Harlow',\n",
       " 'Harrogate',\n",
       " 'Harrow',\n",
       " 'Hart',\n",
       " 'Hartlepool',\n",
       " 'Hastings',\n",
       " 'Havant',\n",
       " 'Havering',\n",
       " 'Herefordshire',\n",
       " 'Hertfordshire',\n",
       " 'Hertsmere',\n",
       " 'High Peak',\n",
       " 'Highland',\n",
       " 'Hillingdon',\n",
       " 'Hinckley and Bosworth',\n",
       " 'Horsham',\n",
       " 'Hounslow',\n",
       " 'Huntingdonshire',\n",
       " 'Hyndburn',\n",
       " 'Inner London',\n",
       " 'Inverclyde',\n",
       " 'Ipswich',\n",
       " 'Isle of Anglesey',\n",
       " 'Isle of Wight',\n",
       " 'Islington',\n",
       " 'Kensington and Chelsea',\n",
       " 'Kent',\n",
       " \"King's Lynn and West Norfolk \",\n",
       " 'Kingston upon Thames',\n",
       " 'Kirklees',\n",
       " 'Knowsley',\n",
       " 'Lambeth',\n",
       " 'Lancashire',\n",
       " 'Lancaster',\n",
       " 'Leeds',\n",
       " 'Leicester',\n",
       " 'Leicestershire',\n",
       " 'Lewes',\n",
       " 'Lewisham',\n",
       " 'Lichfield',\n",
       " 'Lincoln',\n",
       " 'Lincolnshire',\n",
       " 'Lisburn and Castlereagh',\n",
       " 'Liverpool',\n",
       " 'London',\n",
       " 'Luton',\n",
       " 'Maidstone',\n",
       " 'Maldon',\n",
       " 'Malvern Hills',\n",
       " 'Manchester',\n",
       " 'Mansfield',\n",
       " 'Medway',\n",
       " 'Melton',\n",
       " 'Mendip',\n",
       " 'Merseyside',\n",
       " 'Merthyr Tydfil',\n",
       " 'Merton',\n",
       " 'Mid Devon',\n",
       " 'Mid Suffolk',\n",
       " 'Mid Sussex',\n",
       " 'Mid Ulster',\n",
       " 'Mid and East Antrim',\n",
       " 'Middlesbrough',\n",
       " 'Midlothian',\n",
       " 'Milton Keynes',\n",
       " 'Mole Valley',\n",
       " 'Monmouthshire',\n",
       " 'Moray',\n",
       " 'Na h-Eileanan Siar',\n",
       " 'Neath Port Talbot',\n",
       " 'New Forest',\n",
       " 'Newark and Sherwood',\n",
       " 'Newcastle upon Tyne',\n",
       " 'Newcastle-under-Lyme',\n",
       " 'Newham',\n",
       " 'Newport',\n",
       " 'Newry Mourne and Down',\n",
       " 'Norfolk',\n",
       " 'North Ayrshire',\n",
       " 'North Devon',\n",
       " 'North East',\n",
       " 'North East Derbyshire',\n",
       " 'North East Lincolnshire',\n",
       " 'North Hertfordshire',\n",
       " 'North Kesteven',\n",
       " 'North Lanarkshire',\n",
       " 'North Lincolnshire',\n",
       " 'North Norfolk',\n",
       " 'North Northamptonshire',\n",
       " 'North Somerset',\n",
       " 'North Tyneside',\n",
       " 'North Warwickshire',\n",
       " 'North West',\n",
       " 'North West Leicestershire',\n",
       " 'North Yorkshire',\n",
       " 'Northern Ireland',\n",
       " 'Northumberland',\n",
       " 'Norwich',\n",
       " 'Nottinghamshire',\n",
       " 'Nuneaton and Bedworth',\n",
       " 'Oadby and Wigston',\n",
       " 'Oldham',\n",
       " 'Orkney Islands',\n",
       " 'Outer London',\n",
       " 'Oxford',\n",
       " 'Oxfordshire',\n",
       " 'Pembrokeshire',\n",
       " 'Pendle',\n",
       " 'Perth and Kinross',\n",
       " 'Portsmouth',\n",
       " 'Powys',\n",
       " 'Preston',\n",
       " 'Reading',\n",
       " 'Redbridge',\n",
       " 'Redcar and Cleveland',\n",
       " 'Redditch',\n",
       " 'Reigate and Banstead',\n",
       " 'Renfrewshire',\n",
       " 'Rhondda Cynon Taf',\n",
       " 'Ribble Valley',\n",
       " 'Richmond upon Thames',\n",
       " 'Richmondshire',\n",
       " 'Rochdale',\n",
       " 'Rochford',\n",
       " 'Rossendale',\n",
       " 'Rother',\n",
       " 'Rotherham',\n",
       " 'Rugby',\n",
       " 'Runnymede',\n",
       " 'Rushcliffe',\n",
       " 'Rushmoor',\n",
       " 'Rutland',\n",
       " 'Ryedale',\n",
       " 'Salford',\n",
       " 'Sandwell',\n",
       " 'Scarborough',\n",
       " 'Scotland',\n",
       " 'Scottish Borders',\n",
       " 'Sedgemoor',\n",
       " 'Sefton',\n",
       " 'Selby',\n",
       " 'Sevenoaks',\n",
       " 'Sheffield',\n",
       " 'Shetland Islands',\n",
       " 'Shropshire',\n",
       " 'Slough',\n",
       " 'Solihull',\n",
       " 'Somerset',\n",
       " 'Somerset West and Taunton',\n",
       " 'South Ayrshire',\n",
       " 'South Cambridgeshire',\n",
       " 'South Derbyshire',\n",
       " 'South East',\n",
       " 'South Gloucestershire',\n",
       " 'South Hams',\n",
       " 'South Holland',\n",
       " 'South Kesteven',\n",
       " 'South Lakeland',\n",
       " 'South Lanarkshire',\n",
       " 'South Norfolk',\n",
       " 'South Oxfordshire',\n",
       " 'South Ribble',\n",
       " 'South Somerset',\n",
       " 'South Staffordshire',\n",
       " 'South Tyneside',\n",
       " 'South West',\n",
       " 'South Yorkshire',\n",
       " 'Southampton',\n",
       " 'Southend-on-Sea',\n",
       " 'Southwark',\n",
       " 'Spelthorne',\n",
       " 'St Albans',\n",
       " 'St Helens',\n",
       " 'Stafford',\n",
       " 'Staffordshire',\n",
       " 'Staffordshire Moorlands',\n",
       " 'Stevenage',\n",
       " 'Stirling',\n",
       " 'Stockport',\n",
       " 'Stockton-on-Tees',\n",
       " 'Stoke-on-Trent',\n",
       " 'Stratford-on-Avon',\n",
       " 'Stroud',\n",
       " 'Suffolk',\n",
       " 'Sunderland',\n",
       " 'Surrey',\n",
       " 'Surrey Heath',\n",
       " 'Sutton',\n",
       " 'Swale',\n",
       " 'Swansea',\n",
       " 'Swindon',\n",
       " 'Tameside',\n",
       " 'Tamworth',\n",
       " 'Tandridge',\n",
       " 'Teignbridge',\n",
       " 'Telford and Wrekin',\n",
       " 'Tendring',\n",
       " 'Test Valley',\n",
       " 'Tewkesbury',\n",
       " 'Thanet',\n",
       " 'Three Rivers',\n",
       " 'Thurrock',\n",
       " 'Tonbridge and Malling',\n",
       " 'Torbay',\n",
       " 'Torfaen',\n",
       " 'Torridge',\n",
       " 'Tower Hamlets',\n",
       " 'Trafford',\n",
       " 'Tunbridge Wells',\n",
       " 'Tyne and Wear',\n",
       " 'United Kingdom',\n",
       " 'Uttlesford',\n",
       " 'Vale of Glamorgan',\n",
       " 'Vale of White Horse',\n",
       " 'Wakefield',\n",
       " 'Wales',\n",
       " 'Walsall',\n",
       " 'Waltham Forest',\n",
       " 'Wandsworth',\n",
       " 'Warrington',\n",
       " 'Warwick',\n",
       " 'Warwickshire',\n",
       " 'Watford',\n",
       " 'Waverley',\n",
       " 'Wealden',\n",
       " 'Welwyn Hatfield',\n",
       " 'West Berkshire',\n",
       " 'West Devon',\n",
       " 'West Dunbartonshire',\n",
       " 'West Lancashire',\n",
       " 'West Lindsey',\n",
       " 'West Lothian',\n",
       " 'West Midlands',\n",
       " 'West Midlands Region',\n",
       " 'West Northamptonshire',\n",
       " 'West Oxfordshire',\n",
       " 'West Suffolk',\n",
       " 'West Sussex',\n",
       " 'West Yorkshire',\n",
       " 'Wigan',\n",
       " 'Wiltshire',\n",
       " 'Winchester',\n",
       " 'Windsor and Maidenhead',\n",
       " 'Wirral',\n",
       " 'Woking',\n",
       " 'Wokingham',\n",
       " 'Wolverhampton',\n",
       " 'Worcester',\n",
       " 'Worcestershire',\n",
       " 'Worthing',\n",
       " 'Wrexham',\n",
       " 'Wychavon',\n",
       " 'Wyre',\n",
       " 'Wyre Forest',\n",
       " 'York',\n",
       " 'Yorkshire and The Humber']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df2['Region_Name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "import mlflow\n",
    "import prefect\n",
    "from prefect import task, flow, get_run_logger\n",
    "from prefect.task_runners import SequentialTaskRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths() -> str:\n",
    "    PATH_CURRENT = Path.cwd()\n",
    "    NEW_PATH = os.path.join(PATH_CURRENT.parents[3], \"data\", \"uk_house_price\")\n",
    "    DATA_PATH = os.path.join(NEW_PATH, \"Average_price-2022-02_from2000.csv\")\n",
    "    return DATA_PATH\n",
    "\n",
    "def read_data(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    df2 = df.drop(\"Unnamed: 0\", axis=1)\n",
    "    df2[\"Date\"] = pd.to_datetime(df2.Date)\n",
    "    col1 = [\"Average_Price\", \"Average_Price_SA\"]\n",
    "    col2 = [\"Monthly_Change\", \"Annual_Change\"]\n",
    "    df2[col1] = df2[col1].astype(\"float32\")\n",
    "    df2[col2] = df2[col2].astype(\"float16\")\n",
    "    return df2\n",
    "\n",
    "def data_split(df: pd.DataFrame, region_input: str):\n",
    "    df = df[df[\"Region_Name\"] == region_input]\n",
    "    split_date = \"2018-01-01\"\n",
    "    df_train = df.loc[df[\"Date\"] <= split_date].copy()\n",
    "    df_test = df.loc[df[\"Date\"] > split_date].copy()\n",
    "    df_train = df_train[[\"Date\", \"Average_Price\"]].rename(\n",
    "        columns={\"Date\": \"ds\", \"Average_Price\": \"y\"}\n",
    "    )\n",
    "    df_test = df_test[[\"Date\", \"Average_Price\"]].rename(\n",
    "        columns={\"Date\": \"ds\", \"Average_Price\": \"y\"}\n",
    "    )\n",
    "\n",
    "    return df_train, df_test\n",
    "\n",
    "def train_data(df_train: pd.DataFrame, region_input: str):\n",
    "\n",
    "    model = Prophet()\n",
    "    model.fit(df_train)\n",
    "\n",
    "    y_forecast = model.predict(df_train)\n",
    "\n",
    "    y_pred_low, y_pred_up = max(y_forecast[\"yhat_lower\"]), max(y_forecast[\"yhat_upper\"])\n",
    "\n",
    "    y_pred_additive, y_pred_low_additive, y_pred_up_additive = (\n",
    "        max(y_forecast[\"additive_terms\"]),\n",
    "        max(y_forecast[\"additive_terms_lower\"]),\n",
    "        max(y_forecast[\"additive_terms_upper\"]),\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def evaluation(df_test: pd.DataFrame, model):\n",
    "\n",
    "    y_predict = model.predict(df_test)\n",
    "    y_pred_low, y_pred_up = max(y_predict[\"yhat_lower\"]), max(y_predict[\"yhat_upper\"])\n",
    "\n",
    "    y_pred_additive, y_pred_low_additive, y_pred_up_additive = (\n",
    "        max(y_predict[\"additive_terms\"]),\n",
    "       max(y_predict[\"additive_terms_lower\"]),\n",
    "        max(y_predict[\"additive_terms_upper\"]),\n",
    "    )\n",
    "\n",
    "    return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = \"s3://mlopszoomcamp-bucket/UK_house_price/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///mlflow_uk_house.db\")\n",
    "mlflow.create_experiment(\"UK_forecasting\", s3_bucket)\n",
    "mlflow.set_experiment(\"UK_forecasting\")\n",
    "\n",
    "data_path = get_paths()\n",
    "df = read_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:12:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:12:52 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default artifacts URI: 's3://mlopszoomcamp-bucket/UK_house_price/63e642bf3ad44eb090c2d59f896a3165/artifacts'\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"Prophet_forecasting\"):\n",
    "\n",
    "    mlflow.set_tag(\"Region\", \"Leeds\")\n",
    "    newcastle_train, newcastle_test = data_split(df, \"Leeds\")\n",
    "    model = train_data(newcastle_train, \"Leeds\")\n",
    "    y_predict = evaluation(newcastle_test, model)\n",
    "    mlflow.log_metric(\"yhat_lower\", max(y_predict[\"yhat_lower\"]))\n",
    "    mlflow.log_metric(\"yhat_upper\", max(y_predict[\"yhat_upper\"]))\n",
    "\n",
    "    mlflow.log_metric(\"additive_terms\", max(y_predict[\"additive_terms\"]))\n",
    "    mlflow.log_metric(\"additive_terms_lower\", max(y_predict[\"additive_terms_lower\"]))\n",
    "    mlflow.log_metric(\"additive_terms_upper\", max(y_predict[\"additive_terms_upper\"]))\n",
    "\n",
    "\n",
    "    mlflow.prophet.log_model(model, artifact_path=\"models_prophet\")\n",
    "    print(f\"Default artifacts URI: '{mlflow.get_artifact_uri()}'\")\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download artifact with client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "MLFLOW_TRACKING_URi = \"http://ec2-35-177-90-140.eu-west-2.compute.amazonaws.com:5000\"\n",
    "RUN_ID = \"67d71c7dec044fa8a64bf8e4a0b536dc\"\n",
    "\n",
    "client = MlflowClient(tracking_uri=f\"http://{TRACKING_SERVER_HOST}:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/tmpluv4u7z7/'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.download_artifacts(run_id=RUN_ID, path='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTIFACT_URI = \"s3://mlopszoomcamp-bucket/UK_house_price/67d71c7dec044fa8a64bf8e4a0b536dc/artifacts/models_prophet/model.pr\"\n",
    "\n",
    "# path = client.download_artifacts(artifact_uri=ARTIFACT_URI, run_id=RUN_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/tmpjr9x2w62/model.pr'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model = mlflow.artifacts.download_artifacts(artifact_uri=ARTIFACT_URI)\n",
    "\n",
    "load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '\"'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/mlops_zoomcamp/temp/MLOps_Zoomcamp/UK_house_price/mlflow_experiment.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmlops-zoomcamp/home/ubuntu/mlops_zoomcamp/temp/MLOps_Zoomcamp/UK_house_price/mlflow_experiment.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmlops-zoomcamp/home/ubuntu/mlops_zoomcamp/temp/MLOps_Zoomcamp/UK_house_price/mlflow_experiment.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(load_model, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f_out:\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bmlops-zoomcamp/home/ubuntu/mlops_zoomcamp/temp/MLOps_Zoomcamp/UK_house_price/mlflow_experiment.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     loaded_artifact \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(f_out)\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '\"'."
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(load_model, 'rb') as f_out:\n",
    "    loaded_artifact = pickle.load(f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.list_registered_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained model from MLflow artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/prophet/serialize.py:156: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]))\n"
     ]
    }
   ],
   "source": [
    "RUN_ID = \"836ad6fb72de4878a6cafb093bbeb2e3\"\n",
    "\n",
    "logged_model = f'runs:/{RUN_ID}/models_prophet'\n",
    "model_load = mlflow.pyfunc.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "barnsley_train, barnsley_test = data_split(df, \"Barnsley\")\n",
    "y_hat = evaluation(barnsley_test, model_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_additive, y_hat_low_additive, y_hat_up_additive = (\n",
    "        max(y_hat[\"additive_terms\"]),\n",
    "       max(y_hat[\"additive_terms_lower\"]),\n",
    "        max(y_hat[\"additive_terms_upper\"]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1108.7033434177679\n",
      "1108.7033434177679\n",
      "1108.7033434177679\n"
     ]
    }
   ],
   "source": [
    "print(y_hat_additive)\n",
    "print(y_hat_low_additive)\n",
    "print(y_hat_up_additive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Flask on MLFlow Tracking Server (cont. from above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime, date\n",
    "\n",
    "today = date.today()\n",
    "input_date = datetime.strptime(\"2019-01-19\", \"%Y-%m-%d\")\n",
    "\n",
    "df_test = {\n",
    "    \"ds\": [today.strftime(\"%Y-%m-%d\")],\n",
    "    \"y\": [250000]\n",
    "}\n",
    "\n",
    "features = {}\n",
    "features['ds'] = df_test['ds']\n",
    "features['y'] = df_test['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ds': ['2022-08-16'], 'y': [250000]}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.DataFrame.from_dict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_feature = evaluation(feature_df, model_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>trend</th>\n",
       "      <th>yhat_lower</th>\n",
       "      <th>yhat_upper</th>\n",
       "      <th>trend_lower</th>\n",
       "      <th>trend_upper</th>\n",
       "      <th>additive_terms</th>\n",
       "      <th>additive_terms_lower</th>\n",
       "      <th>additive_terms_upper</th>\n",
       "      <th>yearly</th>\n",
       "      <th>yearly_lower</th>\n",
       "      <th>yearly_upper</th>\n",
       "      <th>multiplicative_terms</th>\n",
       "      <th>multiplicative_terms_lower</th>\n",
       "      <th>multiplicative_terms_upper</th>\n",
       "      <th>yhat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-08-16</td>\n",
       "      <td>133448.435609</td>\n",
       "      <td>108242.751517</td>\n",
       "      <td>166478.603978</td>\n",
       "      <td>106027.198984</td>\n",
       "      <td>164232.798517</td>\n",
       "      <td>2385.043976</td>\n",
       "      <td>2385.043976</td>\n",
       "      <td>2385.043976</td>\n",
       "      <td>2385.043976</td>\n",
       "      <td>2385.043976</td>\n",
       "      <td>2385.043976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135833.479586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ds          trend     yhat_lower     yhat_upper    trend_lower  \\\n",
       "0 2022-08-16  133448.435609  108242.751517  166478.603978  106027.198984   \n",
       "\n",
       "     trend_upper  additive_terms  additive_terms_lower  additive_terms_upper  \\\n",
       "0  164232.798517     2385.043976           2385.043976           2385.043976   \n",
       "\n",
       "        yearly  yearly_lower  yearly_upper  multiplicative_terms  \\\n",
       "0  2385.043976   2385.043976   2385.043976                   0.0   \n",
       "\n",
       "   multiplicative_terms_lower  multiplicative_terms_upper           yhat  \n",
       "0                         0.0                         0.0  135833.479586  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_feature['yhat_lower']\n",
    "y_hat_feature['yhat_upper']\n",
    "y_hat_feature['y_hat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_version': '836ad6fb72de4878a6cafb093bbeb2e3', 'y_hat': 135833.47958562724}\n"
     ]
    }
   ],
   "source": [
    "url = 'http://localhost:9696/predict'\n",
    "response = requests.post(url, json=df_test)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Timestamp\n",
    "\n",
    "result_list = [\n",
    "                {'ds': Timestamp('2022-08-16 00:00:00'), 'trend': 133448.43560938345, \n",
    "                'yhat_lower': 106377.57638399057, 'yhat_upper': 167368.69821939082, \n",
    "                'trend_lower': 103667.75665957846, 'trend_upper': 165157.83761481557, \n",
    "                'additive_terms': 2385.0439762437973, 'additive_terms_lower': 2385.0439762437973,\n",
    "                'additive_terms_upper': 2385.0439762437973, 'yearly': 2385.0439762437973,\n",
    "                'yearly_lower': 2385.0439762437973, 'yearly_upper': 2385.0439762437973, \n",
    "                'multiplicative_terms': 0.0, 'multiplicative_terms_lower': 0.0, \n",
    "                'multiplicative_terms_upper': 0.0, 'yhat': 135833.47958562724\n",
    "            }\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-08-16'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.strftime(result_list[0]['ds'], \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative : Testing Flask on Loaded Model from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/prophet/serialize.py:156: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]))\n"
     ]
    }
   ],
   "source": [
    "RUN_ID = \"836ad6fb72de4878a6cafb093bbeb2e3\"\n",
    "\n",
    "logged_model = f's3://mlopszoomcamp-bucket/UK_house_price/{RUN_ID}/artifacts/models_prophet'\n",
    "model_load_s3 = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "input_date = datetime.strptime(\"2019-01-25\", \"%Y-%m-%d\")\n",
    "\n",
    "df_test = {\n",
    "    \"ds\": [input_date.strftime(\"%Y-%m-%d\")],\n",
    "    \"y\": [270000]\n",
    "}\n",
    "\n",
    "features = {}\n",
    "features['ds'] = df_test['ds']\n",
    "features['y'] = df_test['y']\n",
    "\n",
    "feature_df = pd.DataFrame.from_dict(features)\n",
    "\n",
    "y_hat_feature = evaluation(feature_df, model_load_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date': '2019-01-25', 'model_version': '836ad6fb72de4878a6cafb093bbeb2e3', 'y_hat': 122701.50271087937, 'y_hat_lower': 119736.21396832094, 'y_hat_upper': 125906.64659605008}\n"
     ]
    }
   ],
   "source": [
    "url = 'http://localhost:9696/predict'\n",
    "response = requests.post(url, json=df_test)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('env_python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bfffed406ecb5d4cd71a351b5adbe2d4a1f767d87a1721c35bb36573dcf4d5bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
