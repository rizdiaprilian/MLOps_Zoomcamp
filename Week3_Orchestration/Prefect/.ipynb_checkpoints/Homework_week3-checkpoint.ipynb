{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 3 Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this homework is to familiarize users with workflow orchestration. We start from the solution of homework 1. The notebook can be found below:\n",
    "\n",
    "https://github.com/DataTalksClub/mlops-zoomcamp/blob/main/01-intro/homework.ipynb\n",
    "\n",
    "This has already been converted to a script called homework.py in the 03-orchestration folder of this repo.\n",
    "\n",
    "You will use the FHV dataset like in homework 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Converting the script to a Prefect flow\n",
    "\n",
    "If you need Windows support, check `windows.md` for installation instructions.\n",
    "\n",
    "The current script `homework.py` is a fully functional script as long as you already have `fhv_trip_data_2021-01.parquet` and `fhv_trip_data_2021-02.parquet` inside a `data` folder. You should be able to already run it using:\n",
    "```\n",
    "python homework.py\n",
    "```\n",
    "\n",
    "We want to bring this to workflow orchestration to add observability around it. The `main` function will be converted to a `flow` and the other functions will be `tasks`. After adding all of the decorators, there is actually one task that you will need to call `.result()` for inside the `flow` to get it to work. Which task is this?\n",
    "\n",
    "    read_data\n",
    "    prepare_features\n",
    "    train_model\n",
    "    run_model\n",
    "\n",
    "Important: change all `print` statements to use the Prefect logger. Using the `print` statement will not appear in the Prefect UI. You have to call `get_run_logger` at the start of the task to use it.\n",
    "\n",
    "### Answer: train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\github_repos\\mlops-zoomcamp\\data\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PATH = os.path.join(Path(os.getcwd()).parent.parent,'data')\n",
    "print(TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/github_repos/mlops-zoomcamp')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_CUR = os.getcwd()\n",
    "p = Path(PATH_CUR)\n",
    "p.parents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:50:04.159 | INFO    | prefect.engine - Created flow run 'vigorous-lemur' for flow 'log-example-flow'\n",
      "14:50:04.159 | INFO    | Flow run 'vigorous-lemur' - Using task runner 'ConcurrentTaskRunner'\n",
      "14:50:04.192 | WARNING | Flow run 'vigorous-lemur' - No default storage is configured on the server. Results from this flow run will be stored in a temporary directory in its runtime environment.\n",
      "14:50:04.309 | INFO    | Flow run 'vigorous-lemur' - Created task run 'read-parquet-task-d3ed3847-0' for task 'read-parquet-task'\n",
      "14:50:04.372 | INFO    | Task run 'read-parquet-task-d3ed3847-0' - INFO reading parquet files.\n",
      "14:50:04.435 | INFO    | Flow run 'vigorous-lemur' - Created task run 'task-prepare-features-e5923a4a-0' for task 'task-prepare-features'\n",
      "14:50:04.920 | INFO    | Flow run 'vigorous-lemur' - Created task run 'read-parquet-task-d3ed3847-1' for task 'read-parquet-task'\n",
      "14:50:05.028 | INFO    | Flow run 'vigorous-lemur' - Created task run 'task-prepare-features-e5923a4a-1' for task 'task-prepare-features'\n",
      "14:50:07.857 | INFO    | Task run 'read-parquet-task-d3ed3847-1' - INFO reading parquet files.\n",
      "14:50:07.954 | INFO    | Flow run 'vigorous-lemur' - Created task run 'train-model-task-d13a5d1a-0' for task 'train-model-task'\n",
      "14:50:14.717 | INFO    | Task run 'read-parquet-task-d3ed3847-0' - Finished in state Completed()\n",
      "14:50:16.138 | INFO    | Task run 'task-prepare-features-e5923a4a-0' - INFO preparing categorical features & calculating average duration.\n",
      "14:50:16.549 | INFO    | Task run 'read-parquet-task-d3ed3847-1' - Finished in state Completed()\n",
      "14:50:16.870 | INFO    | Task run 'task-prepare-features-e5923a4a-1' - INFO preparing categorical features & calculating average duration.\n",
      "14:50:16.932 | INFO    | Task run 'task-prepare-features-e5923a4a-0' - INFO The mean duration of training is 16.247253368247375\n",
      "14:50:20.822 | INFO    | Task run 'task-prepare-features-e5923a4a-1' - INFO The mean duration of validation is 16.859265811074575\n",
      "14:50:34.396 | INFO    | Task run 'task-prepare-features-e5923a4a-0' - Finished in state Completed()\n",
      "14:50:35.948 | INFO    | Task run 'train-model-task-d13a5d1a-0' - INFO training model.\n",
      "14:50:37.109 | INFO    | Task run 'task-prepare-features-e5923a4a-1' - Finished in state Completed()\n",
      "14:50:41.861 | WARNING | Task run 'train-model-task-d13a5d1a-0' - WARNING DictVectorizer\n",
      "14:50:46.688 | INFO    | Task run 'train-model-task-d13a5d1a-0' - INFO The shape of X_train is (1109826, 525)\n",
      "14:50:46.689 | INFO    | Task run 'train-model-task-d13a5d1a-0' - INFO The DictVectorizer has 525 features\n",
      "14:51:39.619 | INFO    | Task run 'train-model-task-d13a5d1a-0' - INFO The MSE of training is: 10.52851910720414\n",
      "14:51:39.892 | INFO    | Task run 'train-model-task-d13a5d1a-0' - Finished in state Completed()\n",
      "14:51:39.944 | INFO    | Flow run 'vigorous-lemur' - Created task run 'run-model-task-3795006a-0' for task 'run-model-task'\n",
      "14:51:40.274 | INFO    | Task run 'run-model-task-3795006a-0' - INFO running model.\n",
      "14:51:48.768 | INFO    | Task run 'run-model-task-3795006a-0' - The MSE of validation is: 11.014283130405827\n",
      "14:51:48.971 | INFO    | Task run 'run-model-task-3795006a-0' - Finished in state Completed()\n",
      "14:51:57.128 | INFO    | Flow run 'vigorous-lemur' - Finished in state Completed('All states completed.')\n"
     ]
    }
   ],
   "source": [
    "!python homework_with_prefect.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2. Parameterizing the flow\n",
    "\n",
    "Right now there are two parameters for `main()` called `train_path` and `val_path`. We want to change the flow function to accept `date` instead. `date` should then be passed to a task that gives both the `train_path` and `val_path` to use.\n",
    "\n",
    "It should look like this:\n",
    "\n",
    "```\n",
    "@flow\n",
    "def main(date=None):\n",
    "    train_path, val_path = get_paths(date).result()\n",
    "```\n",
    "\n",
    "Because we have two files:\n",
    "\n",
    "    fhv_tripdata_2021-01.parquet\n",
    "    fhv_tripdata_2021-02.parquet\n",
    "\n",
    "Change the `main()` flow call to the following:\n",
    "\n",
    "```\n",
    "main(date=\"2021-03-15\")\n",
    "```\n",
    "\n",
    "and it should use those files. This is a simplification for testing our homework.\n",
    "\n",
    "Download the relevant files needed to run the `main` flow if `date` is 2021-08-15.\n",
    "\n",
    "For example:\n",
    "```\n",
    "main(date=\"2021-08-15\")\n",
    "```\n",
    "By setting up the logger from the previous step, we should see some logs about our training job. What is the validation MSE when running the flow with this date?\n",
    "\n",
    "The validation MSE is:\n",
    "\n",
    "    11.637\n",
    "    11.837\n",
    "    12.037\n",
    "    12.237\n",
    "    \n",
    "### Answer: 11.637\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3. Saving the model and artifacts\n",
    "\n",
    "At the moment, we are not saving the model and vectorizer for future use. You don't need a new task for this, you can just add it inside the `flow`. The requirements for filenames to save it as were mentioned in the Motivation section. They are pasted again here:\n",
    "\n",
    "- Save the model as \"model-{date}.pkl\" where date is in `YYYY-MM-DD`. Note that `date` here is the value of the `flow` parameter. In practice, this setup makes it very easy to get the latest model to run predictions because you just need to get the most recent one.\n",
    "- In this example we use a DictVectorizer. That is needed to run future data through our model. Save that as \"dv-{date}.pkl\". Similar to above, if the date is 2021-03-15, the files output should be `model-2021-03-15.bin` and `dv-2021-03-15.b`.\n",
    "\n",
    "By using this file name, during inference, we can just pull the latest model from our model directory and apply it. Assuming we already had a list of filenames:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['model-2021-03-15.bin', 'model-2021-04-15.bin', 'model-2021-05-15.bin']\n",
    "\n",
    "We could do something like sorted(model_list, reverse=False)[0] to get the filename of the latest file. This is the simplest way to consistently use the latest trained model for inference. Tools like MLFlow give us more control logic to use flows.\n",
    "\n",
    "What is the file size of the DictVectorizer that we trained when the date is 2021-08-15?\n",
    "\n",
    "    13,000 bytes\n",
    "    23,000 bytes\n",
    "    33,000 bytes\n",
    "    43,000 bytes\n",
    "    \n",
    "### Answer: 13,000 bytes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Creating a deployment with a CronSchedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We previously showed the `IntervalSchedule` in the video tutorials. In some cases, the interval is too rigid. For example, what if we wanted to run this flow on the 15th of every month? An interval of 30 days would not be in sync. In cases like these, the CronSchedule is more appropriate. The documentation for that is here\n",
    "\n",
    "Cron is an important part of workflow orchestration. It is used to schedule tasks, and was a predecessor for more mature orchestration frameworks. A lot of teams still use Cron in production. Even if you don't use Cron, the Cron expression is very common as a way to write a schedule, and the basics are worth learning for orchestration, even outside Prefect.\n",
    "\n",
    "For this exercise, use a CronSchedule when creating a Prefect deployment.\n",
    "\n",
    "What is the Cron expression to run a flow at 9 AM every 15th of the month?\n",
    "\n",
    "   - `* * 15 9 0`\n",
    "   - `9 15 * * *`\n",
    "   - `0 9 15 * *`\n",
    "   - `0 15 9 1 *`\n",
    "\n",
    "Hint: there are many Cron to English tools. Try looking for one to help you.\n",
    "\n",
    "### Answer: `0 9 15 * *`\n",
    "\n",
    "Create a deployment with `prefect deployment create` after you write your `DeploymentSpec`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. Viewing the Deployment\n",
    "\n",
    "View the deployment in the UI. When first loading, we may not see that many flows because the default filter is 1 day back and 1 day forward. Remove the filter for 1 day forward to see the scheduled runs.\n",
    "\n",
    "How many flow runs are scheduled by Prefect in advance? You should not be counting manually. There is a number of upcoming runs on the top right of the dashboard.\n",
    "\n",
    "   - 0\n",
    "   - 3\n",
    "   - 10\n",
    "   - 25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Creating a work-queue\n",
    "\n",
    "In order to run this flow, you will need an agent and a work queue. Because we scheduled our flow on every month, it won't really get picked up by an agent. For this exercise, create a work-queue from the UI and view it using the CLI.\n",
    "\n",
    "For all CLI commands with Prefect, you can use `--help` to get more information.\n",
    "\n",
    "For example,\n",
    "\n",
    "    `prefect --help`\n",
    "    `prefect work-queue --help`\n",
    "\n",
    "What is the command to view the available work-queues?\n",
    "\n",
    "   - `prefect work-queue inspect`\n",
    "   - `prefect work-queue ls`\n",
    "   - `prefect work-queue preview`\n",
    "   - `prefect work-queue list`\n",
    "   \n",
    "### Answer: `prefect work-queue ls`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env_python38]",
   "language": "python",
   "name": "conda-env-env_python38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
